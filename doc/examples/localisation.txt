.. highlight:: Matlab

.. _sec-examples-localisation:

Localisation with and without head rotations
============================================

The |TwoEarsModel| comes with several knowledge sources that work together on
getting an estimation of the perceived azimuth of a sound source, see
:ref:`sec-blackboard-localisation` for a summary. The main work is done by the
``LocationKS`` knowledge source how uses :abbr:`ITD (interaural time difference`
and :abbr:`ILD (interaural level difference)` cues provided by the |AFE| and
compares them with learned cues to azimuth maps. At its end it provides a
probability for every azimuth for the source to be located there. This will be
passed on to the ``ConfusionKS`` which looks at the probabilities and decides if
a clear direction can be extracted from this. If not, ``ConfusionSolvingKS`` is
called with then triggers ``RotationKS`` to rotate the head of the listener
(could be in the simulation or of a robot) and start the localisation process
again.

In this example we will see how to set up the model to perform a localisation
task and how to switch on or off the possibility of the model to rotate its
head. This example
can be found in the ``examples/localisation_w_and_wo_head_movements`` folder which
consists of the following files::

    BlackboardNoHeadRotation.xml
    Blackboard.xml
    localise.m
    SceneDescription.xml

The first file we look at is ``SceneDescription.xml``, it defines the actual
acoustic scene in which our virtual head and the sound source will be placed in
order to simulate binaural signals. It looks like this:

.. code-block:: xml

    <?xml version="1.0" encoding="utf-8"?>
    <scene
      BlockSize="4096"
      SampleRate="44100"
      MaximumDelay="0.0"
      NumberOfThreads="1"
      LengthOfSimulation = "5"
      HRIRs="impulse_responses/scut_kemar_anechoic/SCUT_KEMAR_anechoic_1m.sofa">
      <source Radius="1.0"
              Mute="false"
              Type="point"
              Name="SoundSource">
        <buffer ChannelMapping="1"
            Type="noise"/>
      </source>
      <sink Name="Head"
            Position="0 0 0"
            UnitX="1 0 0"
            UnitZ="0 0 1"/>
    </scene>

Here, we define basic things like the sampling rate the length of the stimulus,
the used :abbr:`HRTF (head related transfer function)`, the source material, the
listener position, and the distance between listener and source. For more
documentation on specifying the acoustic scene, see
:ref:`sec-xml-scene-description`.

.. note::

    We don't specify the exact source azimuth here, as we will choose different
    azimuth values later on and set them on the fly from within Matlab.

The next thing we have to do is to specify of what components or model should
consists and what it should actually do. This is done by selecting appropriate
modules for the blackboard stage of the model. This can be configured again in
an :abbr:`XML (extended markdown language)` file. First we look at the
configuration for localisation including head movements:

.. code-block:: xml

    <?xml version="1.0" encoding="utf-8"?>
    <blackboardsystem>

        <dataConnection Type="AuditoryFrontEndKS"/>

        <KS Name="loc" Type="LocationKS">
            <Param Type="char">default</Param>
        </KS>
        <KS Name="conf" Type="ConfusionKS"/>
        <KS Name="confSolv" Type="ConfusionSolvingKS"/>
        <KS Name="rot" Type="RotationKS">
            <Param Type="ref">robotConnect</Param>
        </KS>

        <Connection Mode="replaceOld" Event="AgendaEmpty">
            <source>scheduler</source>
            <sink>dataConnect</sink>
        </Connection>
        <Connection Mode="replaceOld">
            <source>dataConnect</source>
            <sink>loc</sink>
        </Connection>
        <Connection Mode="add">
            <source>loc</source>
            <sink>conf</sink>
        </Connection>
        <Connection Mode="replaceOld" Event="ConfusedLocations">
            <source>conf</source>
            <sink>rot</sink>
        </Connection>
        <Connection Mode="add" Event="ConfusedLocations">
            <source>conf</source>
            <sink>confSolv</sink>
        </Connection>

    </blackboardsystem>

Here, we use different knowledge sources that work together in order to solve
the localisation task. We have ``AuditoryFrontEndKS`` for extract auditory cues
from the ear signals, ``LocationKS``, ``ConfusionKS``, ``ConfusionSolvingKS``,
and ``RotationKS`` for the actual localisation task. The ``Param`` section are
parameters we can pass to the knowledge sources. After setting up which
knowledge sources we will use, we have to connect them. For more information on
configuring the blackboard see :ref:`sec-blackboard-configure`.

In a second configuration file we setting up the same blackboard, but now
disabling its ability to turn the head:

.. code-block:: xml

    <?xml version="1.0" encoding="utf-8"?>
    <blackboardsystem>

        <dataConnection Type="AuditoryFrontEndKS"/>

        <KS Name="loc" Type="LocationKS">
            <Param Type="char">default</Param>
        </KS>
        <KS Name="conf" Type="ConfusionKS">
            <!-- Disable confusion solving (== no head rotation) -->
            <Param Type="int">0</Param>
        </KS>

        <Connection Mode="replaceOld" Event="AgendaEmpty">
            <source>scheduler</source>
            <sink>dataConnect</sink>
        </Connection>
        <Connection Mode="replaceOld">
            <source>dataConnect</source>
            <sink>loc</sink>
        </Connection>
        <Connection Mode="add">
            <source>loc</source>
            <sink>conf</sink>
        </Connection>
    </blackboardsystem>

Now, everything is prepared and we can start Matlab in order to perform the
localisation. You can just start it and run the following command to see it in
action, afterwards we will have a look at what happened::

    >> localise

    ------------------------------------------------------------------
    Source direction        Model w head rot.       Model wo head rot.
    ------------------------------------------------------------------
       0                        1                     176
      33                       34                      33
      76                       75                      72
    -121                     -119                    -111
    ------------------------------------------------------------------


.. vim: filetype=rst spell:
