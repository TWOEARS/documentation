.. highlight:: Matlab

.. _sec-examples-train-identification:

Train sound type identification models
======================================

Part of the |TwoEarsModel| is the :ref:`sec-identity-knowledge-source` which can be instantiated (multiple times) to identify the type of auditory objects, like "speech", "fire", "knock" etc. Each IdentityKS needs a source type model -- this example shows one possibility to train such a model. Have a look at the :ref:`sec-examples-identification` to see how these models are being used in the |TwoEars| |blackboard|!.

The base folder for this example is :file:`examples/train_identification_model`, with the main example script file being :file:`trainAndTestCleanModel.m`. Other than that and of relevance, there is only the file :file:`identTraining_repos.xml`, which is the |TwoEars| Toolbox dependencies configuration file. Later in the model training process, new directories with names like "Training.2015.08.03.14.57.21.786" will be created by the training pipeline, holding log files of the training, file lists of the used training and testing data, and of course the trained models. These are the models to be used in the IdentityKS, then.


Example step-through
--------------------

To dive into the example, load up Matlab, navigate into the example directory, and open :file:`trainAndTestCleanModel.m`, which contains a function (also usable as a script). Let's have a look before firing it up!


Dependencies
~~~~~~~~~~~~

First thing happening in there is the ::
    
    startTwoEars( 'Config.xml' );

command. Looking into this file, we see exactly one dependency: to execute this example, we need to load the :ref:`sec-idTrainPipeline` module. The loading process then in turn takes care of initialising also the modules that the training pipeline depends on.


Feature and model creators
~~~~~~~~~~~~~~~~~~~~~~~~~~

The next "paragraph" first creates the basic pipeline object of type :ref:`sec-TwoEarsIdTrainPipe`, and then sets two defining options: The *feature creator* and the *model creator*. ::

   pipe = TwoEarsIdTrainPipe();
   pipe.featureCreator = featureCreators.FeatureSet1Blockmean();
   pipe.modelCreator = modelTrainers.GlmNetLambdaSelectTrainer( ...
       'performanceMeasure', @performanceMeasures.BAC2, ...
       'cvFolds', 7, ...
       'alpha', 0.99 );

In this case, an L1-regularized sparse logistic regression model will be trained through the use of the :ref:`sec-GlmNetLambdaSelectTrainer`, which is a wrapper for `GLMNET <http://web.stanford.edu/~hastie/glmnet_matlab/>`_. A pile of auditory features will be used in this model, processed and compiled by the :ref:`sec-FeatureSet1Blockmean` feature creator. Have a look into the respective sections to learn more!


Training and testing sets
~~~~~~~~~~~~~~~~~~~~~~~~~

The models will be trained using a particular set of sounds, specified in the :ref:`trainset flist <sec-trainset>`. For this example, the IEEE AASP single event sounds serve as training material. There are sounds for several classes like "laughter", "keys", "speech", etc. If you don't call the `trainAndTestCleanModel` function with a different classname, a model for the "speech" class will be trained (this is specified in the third line). Irregardless of the class the model is trained for, all sounds listed in the flist (`have a look <https://dev.qu.tu-berlin.de/projects/twoears-database/repository/revisions/master/entry/learned_models/IdentityKS/trainTestSets/IEEE_AASP_80pTrain_TrainSet_1.flist>`_) will be used for training -- but only the ones belonging to the model class will serve as "positive" examples. ::

   pipe.trainset = 'learned_models/IdentityKS/trainTestSets/IEEE_AASP_80pTrain_TrainSet_1.flist';
   pipe.testset = 'learned_models/IdentityKS/trainTestSets/IEEE_AASP_80pTrain_TestSet_1.flist';

The testset specifies files used for testing the trained model. This is not necessary for the model creation, it only serves as an immediate way of providing feedback about the model performance after training. Of course the testset must only contain files that have not been used for training, to test for generalisation of the model.


Scene configuration
~~~~~~~~~~~~~~~~~~~

A "clean" :ref:`scene configuration <sec-sceneConfiguration>` is used to train this model. That means: the sound sources are positioned at 0Â° azimuth relative to the head, there is no interfering noise, and no reverb (free-field conditions). Have a look into the :ref:`respective training pipeline documentation part <sec-sceneConfiguration>` to get to know the many possibilities to configure the acoustic training scene. ::

   sc = dataProcs.SceneConfiguration(); % clean
   pipe.setSceneConfig( [sc] ); 

   
Running the pipeline
~~~~~~~~~~~~~~~~~~~~

Bla. Text about what to expect, aborting, restarting and so on.

::

   modelPath = pipe.pipeline.run( {classname}, 0 );



.. vim: filetype=rst spell:
